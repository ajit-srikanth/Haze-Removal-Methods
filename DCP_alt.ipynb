{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cumulative_sum(input_image, r):\n",
    "    height, width = input_image.shape\n",
    "    cumulative_sum = np.zeros_like(input_image)\n",
    "\n",
    "    # Calculate cumulative sum for columns\n",
    "    cumulative = np.cumsum(input_image, axis=0)\n",
    "    cumulative_sum[:r+1, :] = cumulative[r:2*r+1, :]\n",
    "    cumulative_sum[r+1:height-r, :] = cumulative[2*r+1:height, :] - cumulative[:height-2*r-1, :]\n",
    "    cumulative_sum[height-r:, :] = np.tile(cumulative[height-1, :], (r, 1)) - cumulative[height-2*r-1:height-r-1, :]\n",
    "\n",
    "    # Calculate cumulative sum for rows\n",
    "    cumulative = np.cumsum(cumulative_sum, axis=1)\n",
    "    cumulative_sum[:, :r+1] = cumulative[:, r:2*r+1]\n",
    "    cumulative_sum[:, r+1:width-r] = cumulative[:, 2*r+1:width] - cumulative[:, :width-2*r-1]\n",
    "    cumulative_sum[:, width-r:] = np.tile(cumulative[:, width-1][:, np.newaxis], (1, r)) - cumulative[:, width-2*r-1:width-r-1]\n",
    "\n",
    "    return cumulative_sum\n",
    "\n",
    "def my_minfilter(I, window_size):\n",
    "    I_new = I.copy()\n",
    "    height, width = I.shape\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            i_down = max(0, i - window_size)\n",
    "            i_up = min(height, i + window_size + 1)\n",
    "            j_down = max(0, j - window_size)\n",
    "            j_up = min(width, j + window_size + 1)\n",
    "            \n",
    "            I_new[i, j] = np.min(I[i_down:i_up, j_down:j_up])\n",
    "\n",
    "    return I_new\n",
    "\n",
    "def my_darkchannel(I, window_size):\n",
    "    height, width, _ = I.shape\n",
    "    dark_channel = np.ones((height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            dark_channel[i, j] = np.min(I[i, j, :])\n",
    "\n",
    "    min_dark_channel = my_minfilter(dark_channel, window_size)\n",
    "    return min_dark_channel\n",
    "\n",
    "def my_estimateA(I, dark_channel):\n",
    "    A = np.zeros((1, 1, 3))\n",
    "    height, width = dark_channel.shape\n",
    "\n",
    "    points_number = round(width * height * 0.001)\n",
    "\n",
    "    for _ in range(points_number):\n",
    "        # brightest_points = np.max(dark_channel)\n",
    "        i, j = np.unravel_index(np.argmax(dark_channel), dark_channel.shape)\n",
    "        \n",
    "        dark_channel[i, j] = 0\n",
    "\n",
    "        if np.mean(I[i, j, :]) > np.mean(A):\n",
    "            A[0, 0, :] = (A[0, 0, :] + I[i, j, :]) / 2\n",
    "\n",
    "    return A\n",
    "\n",
    "def my_guidedfilter(guide_image, I, radius, smooth_parameter):\n",
    "    height, width = guide_image.shape\n",
    "    N = my_cumulative_sum(np.ones((height, width)), radius)\n",
    "\n",
    "    mean_guide = my_cumulative_sum(guide_image, radius) / N\n",
    "    mean_I = my_cumulative_sum(I, radius) / N\n",
    "    mean_IG = my_cumulative_sum(guide_image * I, radius) / N\n",
    "    cov_IG = mean_IG - mean_guide * mean_I\n",
    "    mean_II = my_cumulative_sum(guide_image * guide_image, radius) / N\n",
    "    var_I = mean_II - mean_guide * mean_guide\n",
    "\n",
    "    a = cov_IG / (var_I + smooth_parameter)\n",
    "    b = mean_I - a * mean_guide\n",
    "\n",
    "    mean_a = my_cumulative_sum(a, radius) / N\n",
    "    mean_b = my_cumulative_sum(b, radius) / N\n",
    "\n",
    "    q = mean_a * guide_image + mean_b\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DCP(I, threshold=0.01):\n",
    "\n",
    "    # Get dark channel\n",
    "    window_size = 7\n",
    "    dark_channel = my_darkchannel(I, window_size)\n",
    "    dark_channel = dark_channel / 255.0\n",
    "\n",
    "    # Calculate atmospheric light A\n",
    "    I = I.astype(np.float32) / 255.0\n",
    "    A = my_estimateA(I, dark_channel)\n",
    "\n",
    "    # Calculate transmission matrix t(x)\n",
    "    w = 0.95\n",
    "    t = 1 - w * dark_channel / np.mean(A)\n",
    "\n",
    "    I_gray = cv2.cvtColor(I, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    t1 = my_guidedfilter(I_gray, t, 135, 0.0002)\n",
    "    t2 = my_guidedfilter(t1, t1, 7, 0.03)\n",
    "\n",
    "    # t_threshold = 0.01\n",
    "    t = np.maximum(t2, threshold)\n",
    "\n",
    "    # Recover haze-free image\n",
    "    K = 0.2\n",
    "    defog_image = np.zeros_like(I)\n",
    "\n",
    "    epsilon = 0.000001\n",
    "    for i in range(3):\n",
    "        defog_image[:, :, i] = (\n",
    "            (I[:, :, i] - A[0, 0, i])\n",
    "            / np.minimum(1, t * np.maximum(K / (np.abs(I[:, :, i]+epsilon) - A[0, 0, i]), 1))\n",
    "        ) + A[0, 0, i]\n",
    "\n",
    "    defog_image = defog_image * 1.3\n",
    "    defog_image = np.clip(defog_image, 0, 1)\n",
    "    \n",
    "    return defog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    \"./images/4_CLAHE.jpg\"\n",
    "]\n",
    "\n",
    "for image in images:\n",
    "    inp = cv2.imread(image)\n",
    "    res = run_DCP(inp, 0.05)\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(inp, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Image\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"After DCP\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def my_clip_histogram(hist, sum_pixel_bin, clip_limit, subpart_x, subpart_y):\n",
    "    \"\"\"\n",
    "    Clip histogram to limit contrast enhancement\n",
    "    \"\"\"\n",
    "    for i in range(subpart_x):\n",
    "        for j in range(subpart_y):\n",
    "            # Calculate excess histogram values\n",
    "            sum_excess = 0\n",
    "            for nr in range(sum_pixel_bin):\n",
    "                excess = hist[i, j, nr] - clip_limit\n",
    "                if excess > 0:\n",
    "                    sum_excess += excess\n",
    "\n",
    "            # Redistribute excess histogram values\n",
    "            bin_average = sum_excess / sum_pixel_bin\n",
    "            upper = clip_limit - bin_average\n",
    "\n",
    "            for nr in range(sum_pixel_bin):\n",
    "                if hist[i, j, nr] > clip_limit:\n",
    "                    hist[i, j, nr] = clip_limit\n",
    "                else:\n",
    "                    if hist[i, j, nr] > upper:\n",
    "                        sum_excess += upper - hist[i, j, nr]\n",
    "                        hist[i, j, nr] = clip_limit\n",
    "                    else:\n",
    "                        sum_excess -= bin_average\n",
    "                        hist[i, j, nr] += bin_average\n",
    "\n",
    "            # Distribute remaining excess\n",
    "            if sum_excess > 0:\n",
    "                step_size = max(1, int(1 + sum_excess / sum_pixel_bin))\n",
    "                for nr in range(sum_pixel_bin):\n",
    "                    sum_excess -= step_size\n",
    "                    hist[i, j, nr] += step_size\n",
    "                    if sum_excess < 1:\n",
    "                        break\n",
    "\n",
    "    return hist\n",
    "\n",
    "def my_map_histogram(hist, min_pixel, max_pixel, sum_pixel_bins, sum_pixels, subpart_x, subpart_y):\n",
    "    \"\"\"\n",
    "    Map histogram to output range\n",
    "    \"\"\"\n",
    "    output = np.zeros((subpart_x, subpart_y, sum_pixel_bins))\n",
    "    scale = (max_pixel - min_pixel) / sum_pixels\n",
    "\n",
    "    for i in range(subpart_x):\n",
    "        for j in range(subpart_y):\n",
    "            cumsum = 0\n",
    "            for nr in range(sum_pixel_bins):\n",
    "                cumsum += hist[i, j, nr]\n",
    "                output[i, j, nr] = min(min_pixel + cumsum * scale, max_pixel)\n",
    "\n",
    "    return output\n",
    "\n",
    "def my_adapthisteq(img_gray):\n",
    "    \"\"\"\n",
    "    Adaptive Histogram Equalization implementation\n",
    "    \"\"\"\n",
    "    # Ensure image is float type\n",
    "    img_gray = img_gray.astype(np.float32)\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = img_gray.shape\n",
    "\n",
    "    # Get pixel value range\n",
    "    min_pixel = np.min(img_gray)\n",
    "    max_pixel = np.max(img_gray)\n",
    "\n",
    "    # Image subdivision\n",
    "    subpart_y = max(1, int(width / 100) - 2)\n",
    "    subpart_x = max(1, int(height / 100) - 1)\n",
    "\n",
    "    height_size = int(np.ceil(height / subpart_x))\n",
    "    width_size = int(np.ceil(width / subpart_y))\n",
    "\n",
    "    # Adjust image dimensions to ensure perfect division\n",
    "    delta_y = subpart_x * height_size - height\n",
    "    delta_x = subpart_y * width_size - width\n",
    "\n",
    "    # Pad image\n",
    "    temp_image = np.zeros((height + delta_y, width + delta_x), dtype=np.float32)\n",
    "    temp_image[:height, :width] = img_gray\n",
    "\n",
    "    new_width = width + delta_x\n",
    "    new_height = height + delta_y\n",
    "    sum_pixels = width_size * width_size\n",
    "\n",
    "    # Pixel bin mapping\n",
    "    sum_pixel_bins = 256\n",
    "    \n",
    "    # Create pixel bin with proper indexing\n",
    "    pixel_bin = np.zeros_like(temp_image, dtype=np.int32)\n",
    "    for m in range(temp_image.shape[0]):\n",
    "        for n in range(temp_image.shape[1]):\n",
    "            # Ensure value is within 0-255 range and add 1 for 1-based indexing\n",
    "            pixel_bin[m, n] = min(max(0, int(temp_image[m, n])), 255) + 1\n",
    "\n",
    "    # Create histogram\n",
    "    hist = np.zeros((subpart_x, subpart_y, 256), dtype=np.float32)\n",
    "    for i in range(subpart_x):\n",
    "        for j in range(subpart_y):\n",
    "            sub_img = pixel_bin[i * height_size:(i + 1) * height_size, \n",
    "                                 j * width_size:(j + 1) * width_size]\n",
    "            hist[i, j, :], _ = np.histogram(sub_img, bins=256, range=(1, 257))\n",
    "\n",
    "    # Clip histogram\n",
    "    clip_limit = 2.5\n",
    "    clip_limit = max(1, clip_limit * height_size * width_size / sum_pixel_bins)\n",
    "    hist = my_clip_histogram(hist, sum_pixel_bins, clip_limit, subpart_x, subpart_y)\n",
    "\n",
    "    # Map histogram\n",
    "    map_output = my_map_histogram(hist, min_pixel, max_pixel, sum_pixel_bins, sum_pixels, subpart_x, subpart_y)\n",
    "\n",
    "    # Bilinear interpolation for output\n",
    "    output = np.zeros_like(pixel_bin, dtype=np.float32)\n",
    "    y_i = 0\n",
    "    for i in range(subpart_x + 1):\n",
    "        # Handle row boundaries\n",
    "        if i == 0:\n",
    "            sub_y = int(height_size / 2)\n",
    "            y_up = 0\n",
    "            y_bottom = 0\n",
    "        elif i == subpart_x:\n",
    "            sub_y = int(height_size / 2)\n",
    "            y_up = subpart_x - 1\n",
    "            y_bottom = subpart_x - 1\n",
    "        else:\n",
    "            sub_y = height_size\n",
    "            y_up = i - 1\n",
    "            y_bottom = i\n",
    "\n",
    "        x_i = 0\n",
    "        for j in range(subpart_y + 1):\n",
    "            # Handle column boundaries\n",
    "            if j == 0:\n",
    "                sub_x = int(width_size / 2)\n",
    "                x_left = 0\n",
    "                x_right = 0\n",
    "            elif j == subpart_y:\n",
    "                sub_x = int(width_size / 2)\n",
    "                x_left = subpart_y - 1\n",
    "                x_right = subpart_y - 1\n",
    "            else:\n",
    "                sub_x = width_size\n",
    "                x_left = j - 1\n",
    "                x_right = j\n",
    "\n",
    "            # Interpolation\n",
    "            u_l = map_output[y_up, x_left, :]\n",
    "            u_r = map_output[y_up, x_right, :]\n",
    "            b_l = map_output[y_bottom, x_left, :]\n",
    "            b_r = map_output[y_bottom, x_right, :]\n",
    "\n",
    "            sub_image = pixel_bin[y_i:y_i + sub_y, x_i:x_i + sub_x]\n",
    "            s_image = np.zeros_like(sub_image, dtype=np.float32)\n",
    "\n",
    "            for m in range(sub_y):\n",
    "                for n in range(sub_x):\n",
    "                    val = sub_image[m, n] - 1  # Adjust index\n",
    "                    s_image[m, n] = (\n",
    "                        (sub_y - m) * ((sub_x - n) * u_l[val] + n * u_r[val]) +\n",
    "                        m * ((sub_x - n) * b_l[val] + n * b_r[val])\n",
    "                    ) / (sub_y * sub_x)\n",
    "\n",
    "            output[y_i:y_i + sub_y, x_i:x_i + sub_x] = s_image\n",
    "            x_i += sub_x\n",
    "\n",
    "        y_i += sub_y\n",
    "\n",
    "    # Crop back to original dimensions\n",
    "    output = output[:height, :width]\n",
    "    return output.astype(np.uint8)\n",
    "\n",
    "def run_CLAHE(img):\n",
    "    \"\"\"\n",
    "    Process multiple images using CLAHE\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_img)\n",
    "\n",
    "    # Apply adaptive histogram equalization to L channel\n",
    "    l_enhanced = my_adapthisteq(l_channel)\n",
    "\n",
    "    # Subtract 50 from L channel\n",
    "    l_enhanced = np.clip(l_enhanced.astype(np.float32) - 50, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Merge channels back\n",
    "    enhanced_lab_img = cv2.merge([l_enhanced, a_channel, b_channel])\n",
    "\n",
    "    # Convert back to BGR\n",
    "    enhanced_img = cv2.cvtColor(enhanced_lab_img, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Increase brightness\n",
    "    enhanced_img = np.clip(1.35 * enhanced_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return enhanced_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLAHE_DCP(images, weighted=False, only_DCP_threshold=0.1, CLAHE_DCP_threshold=0.05):\n",
    "    for image_path in images:\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        after_CLAHE = run_CLAHE(img)\n",
    "        after_DCP = run_DCP(after_CLAHE*0.5 + img*0.5, threshold=CLAHE_DCP_threshold) if weighted else run_DCP(after_CLAHE, threshold=CLAHE_DCP_threshold)\n",
    "    \n",
    "        only_DCP = run_DCP(img, threshold=only_DCP_threshold)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"original image\")\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(cv2.cvtColor(after_CLAHE, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"only CLAHE\")\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(cv2.cvtColor(after_DCP, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"CLAHE + DCP\")\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(cv2.cvtColor(only_DCP, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"only DCP\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./images/new_images\"\n",
    "\n",
    "images = [\n",
    "    f\"{folder}/{i}.jpg\" for i in range(2, 3)\n",
    "    ]\n",
    "\n",
    "CLAHE_DCP(images, only_DCP_threshold=0.1, CLAHE_DCP_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./images\"\n",
    "\n",
    "images = [\n",
    "    f\"{folder}/carrrr.png\",\n",
    "    f\"{folder}/delhi.png\",\n",
    "    f\"{folder}/foggy_lil.png\",\n",
    "    f\"{folder}/test_d1.png\",\n",
    "    f\"{folder}/test_paper.png\",\n",
    "    f\"{folder}/test1.png\"\n",
    "]\n",
    "\n",
    "CLAHE_DCP(images, weighted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homomorphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft2, ifft2, fftshift, ifftshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_homofilter(I_mean):\n",
    "    # Step 1: Take logarithm and perform Fourier transform\n",
    "    I_log = np.log(I_mean + 1)\n",
    "    I_fft = fft2(I_log)\n",
    "    I_fft = fftshift(I_fft)\n",
    "\n",
    "    # Step 2: Frequency domain Gaussian high-pass filtering\n",
    "    \n",
    "    # Gaussian filter parameters\n",
    "    L = 0.3\n",
    "    H = 1.8\n",
    "    C = 2\n",
    "    # Cutoff frequency D0\n",
    "    D0 = 1\n",
    "\n",
    "    # Create mask\n",
    "    height, width = I_mean.shape\n",
    "    y, x = np.ogrid[:height, :width]\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "    D = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "    mask = (H - L) * (1 - np.exp(C * (-D / D0))) + L  # Gaussian homomorphic filter\n",
    "\n",
    "    # Apply mask\n",
    "    I_fft_gauss = mask * I_fft\n",
    "    \n",
    "    # Step 3: Inverse Fourier transform and take exponent\n",
    "    I_fft_gauss = ifftshift(I_fft_gauss)\n",
    "    \n",
    "    I_ifft = ifft2(I_fft_gauss)\n",
    "    # Take exponent to restore original image\n",
    "    I_gray_defog = np.real(np.exp(I_ifft) - 1)\n",
    "    \n",
    "    return I_gray_defog\n",
    "\n",
    "\n",
    "def run_Homomorphic(I):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Homomorphic filtering\n",
    "    I_mean = np.mean(I, axis=2)\n",
    "    # I_mean = I_mean.astype(np.float64) / 255.0    \n",
    "    I_mean = np.clip(I_mean, 1e-6, None).astype(np.float64) / 255.0\n",
    "\n",
    "\n",
    "    I_gray_defog = My_homofilter(I_mean)\n",
    "\n",
    "    max_pixel = np.max(I_gray_defog)\n",
    "    I_gray_defog = (I_gray_defog - np.min(I_gray_defog)) / (max_pixel - np.min(I_gray_defog))\n",
    "\n",
    "    # Apply homomorphic filter result to each channel\n",
    "    I_defog = np.zeros_like(I, dtype=np.float64)\n",
    "    for i in range(3):\n",
    "        I_defog[:,:,i] = (I[:,:,i].astype(np.float64) * I_gray_defog) / I_mean\n",
    "\n",
    "    max_pixel = np.max(I_defog)\n",
    "    min_pixel = np.min(I_defog)\n",
    "    I_defog = (I_defog - min_pixel) / (max_pixel - min_pixel)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    I_defog = 1.35 * I_defog\n",
    "    \n",
    "    # normalize the image to [0, 255]\n",
    "    max_pixel = np.max(I_defog)\n",
    "    I_defog = ((255/max_pixel) * I_defog).astype(np.uint8)\n",
    "\n",
    "    end_time = time.time()\n",
    "    # print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "    \n",
    "    return I_defog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Homo_DCP(images, weighted=False):\n",
    "    for image_path in images:\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        after_Homomorphic = run_Homomorphic(img)\n",
    "        after_DCP = run_DCP(after_Homomorphic*0.5 + img*0.5) if weighted else run_DCP(after_Homomorphic)\n",
    "    \n",
    "        only_DCP = run_DCP(img)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"original image\")\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(cv2.cvtColor(after_Homomorphic, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"only Homomorphic\")\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(cv2.cvtColor(after_DCP, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Homomorphic + DCP\")\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(cv2.cvtColor(only_DCP, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"only DCP\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./images\"\n",
    "\n",
    "images = [\n",
    "    f\"{folder}/foggy_lil.png\",\n",
    "    f\"{folder}/carrrr.png\",\n",
    "    f\"{folder}/delhi.png\",\n",
    "    f\"{folder}/test_d1.png\",\n",
    "    f\"{folder}/test_paper.png\",\n",
    "    f\"{folder}/test1.png\"\n",
    "]\n",
    "\n",
    "Homo_DCP(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./images/new_images\"\n",
    "\n",
    "images = [\n",
    "    f\"{folder}/{i}.jpg\" for i in range(1, 9)\n",
    "    ]\n",
    "\n",
    "Homo_DCP(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
